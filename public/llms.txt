# Open Responses

> Open Responses is an open, vendor-neutral specification for large language model APIs that defines a shared schema, consistent streaming/events, and extensible tooling to enable interoperable LLM workflows across different providers. It standardizes LLM interfaces while maintaining flexibility for provider-specific extensions and advanced agentic capabilities. The specification centers on an agentic loop that lets models emit tool calls, receive results, and continue, with items as the atomic unit of context and semantic streaming events for predictable, provider-agnostic clients.

## Core Concepts

- **Items**: The fundamental unit of context in Open Responses; atomic units of model output, tool invocation, or reasoning state. Items are polymorphic (discriminated by `type` field), state machines (with `in_progress`, `completed`, `failed` states), streamable (through delta events), and extensible (with provider-specific prefixes like `openai:web_search_call`).
- **Agentic Loop**: Core principle enabling intelligent interaction, reasoning, and tool invocation for complex workflows. Models analyze requests, determine if tools are needed, and issue tool calls as required, then continue processing based on tool results. The loop consists of reasoning, tool invocation, and response generation phases.
- **Semantic Streaming**: Streaming modeled as semantic events (not raw text deltas) for predictable, provider-agnostic clients. Events describe meaningful transitions like state changes (`response.in_progress`, `response.completed`) or content deltas (`response.output_text.delta`).
- **State Machines**: Objects in Open Responses follow defined state machines with valid state transitions. Items can be `in_progress` (model sampling), `incomplete` (token budget exhausted), or `completed` (fully processed). All state transitions are explicitly defined in the specification.
- **Items → Items**: Bidirectional concept where items can be provided as inputs to the model or received as outputs from the model, enabling flexible conversation patterns and context management.
- **Multi-Provider**: One schema that can map cleanly to many model providers (OpenAI, Anthropic, Gemini, local models, etc.) while preserving semantic meaning across providers.

## API Specification

### HTTP Protocol
- **Requests**: All messages follow the HTTP protocol with `Authorization` and `Content-Type: application/json` headers
- **Non-streaming Responses**: Return data as `application/json`
- **Streaming Responses**: Return header `Content-Type: text/event-stream` with individual `data` objects as JSON-encoded strings, ending with literal string `[DONE]`
- **Event Format**: The `event` field must match the `type` in the event body. Servers should not use IDs.

### Main Endpoint
- `POST /v1/responses`: Creates a response with the specified parameters

### Request Parameters
- `model` (string): The model to use for this request (e.g., 'gpt-5.2')
- `input` (string|array): Context to provide to the model (string interpreted as user message, or array of input items)
- `previous_response_id` (string): ID of the response to use as the prior turn for continuing conversations
- `tools` (array): List of tools that the model may call while generating the response
- `tool_choice` (string|object): Controls which tool the model should use ('auto', 'required', 'none', or specific tool)
- `allowed_tools` (array): Limits which tools the model is permitted to invoke, without changing the tools list itself
- `stream` (boolean): Whether to stream response events as server-sent events
- `temperature` (number): Sampling temperature (0-2), higher values make output more random
- `top_p` (number): Nucleus sampling parameter (0-1), considers tokens with top cumulative probability
- `max_output_tokens` (integer): Maximum number of tokens the model may generate
- `parallel_tool_calls` (boolean): Whether the model may call multiple tools in parallel
- `truncation` (enum): Controls how input is truncated when exceeding context window ('auto', 'disabled')
- `service_tier` (enum): Hint to provider about urgency and reliability ('auto', 'default', 'flex', 'priority')

### Response Structure
- `id` (string): Unique ID of the response that was created
- `object` (string): Object type, always "response"
- `created_at` (integer): Unix timestamp for when the response was created
- `completed_at` (integer): Unix timestamp for when the response was completed (if applicable)
- `status` (string): Status of the response ('queued', 'in_progress', 'completed', 'failed', 'incomplete')
- `model` (string): The model that generated this response
- `output` (array): Output items generated by the model
- `usage` (object): Token usage statistics for the response
- `error` (object): Error details if the response failed

### Streaming Events
- `response.created`: Initial response creation event
- `response.queued`: Response has been queued for processing
- `response.in_progress`: Response has started processing
- `response.output_item.added`: New output item added to the response
- `response.content_part.added`: New content part added to an item
- `response.output_text.delta`: Text content delta for an item
- `response.output_text.done`: Text content for an item is complete
- `response.content_part.done`: Content part for an item is complete
- `response.output_item.done`: Output item is complete
- `response.completed`: Response is fully completed
- `response.failed`: Response failed with an error
- `response.incomplete`: Response is incomplete (e.g., due to token limits)
- `response.function_call_arguments.delta`: Arguments delta for a function call
- `response.function_call_arguments.done`: Function call arguments are complete
- `response.refusal.delta`: Delta for a refusal message
- `response.refusal.done`: Refusal message is complete
- `response.reasoning.delta`: Delta for reasoning content
- `response.reasoning.done`: Reasoning content is complete
- `response.reasoning_summary.delta`: Delta for reasoning summary
- `response.reasoning_summary.done`: Reasoning summary is complete

## Item Types

- **Message Items**: Represent user, assistant, or system messages with role and content
  - `role`: 'user', 'assistant', or 'system'
  - `content`: Array of content parts (text, image, or file inputs)
  - `status`: Lifecycle indicator ('in_progress', 'completed', 'failed')
- **Function Call Items**: Represent function/tool invocations with name and arguments
  - `name`: Name of the function to call
  - `arguments`: JSON string of arguments to pass to the function
  - `call_id`: Identifier for the function call
- **Reasoning Items**: Expose model's internal thought process with content, summary, and encrypted_content fields
  - `summary`: Reasoning summary content
  - `content`: Raw reasoning trace (optional)
  - `encrypted_content`: Protected reasoning content (optional)
- **Tool Call Items**: Represent various types of tool calls (function, file search, web search, code interpreter, etc.)
  - `type`: The type of tool being called
  - `name`: Name of the tool
  - `arguments`: Arguments for the tool call
- **Refusal Items**: Represent model refusals to respond to certain requests
- **Item Reference**: Internal identifier for referencing items

## Content Types

- **User Content vs Model Content**: Two distinct content unions to handle the asymmetric nature of conversation turns
  - **UserContent**: Structured data provided by the user or client application (supports multiple modalities)
  - **ModelContent**: Structured data returned by the model (typically text-focused)
- **Input Text Content**: Text input to the model with `type: "input_text"` and `text` field
- **Input Image Content**: Image input with `type: "input_image"`, `image_url`, and `detail` level ('low', 'high', 'auto')
- **Input File Content**: File input with `type: "input_file"`, `filename`, `file_data`, or `file_url`
- **Output Text Content**: Text output from the model with `type: "output_text"` and `text` field
- **Output Text Annotations**: Text with annotations for highlighting, citations, etc.

## Reasoning Items

- **Purpose**: Expose the model's internal thought process in a controlled, provider-defined way
- **Fields**:
  - `content`: Raw reasoning trace (optional, may be disabled for safety)
  - `encrypted_content`: Protected reasoning content (provider-specific format)
  - `summary`: Summarized view of the reasoning trace (safe for end users)
- **Streaming**: Reasoning content is typically streamable with delta semantics

## Tool Support

- **Externally-hosted Tools**: Implementation lives outside the model provider's system (e.g., functions where developer runs the function and returns output)
- **Internally-hosted Tools**: Implementation lives inside the model provider's system (e.g., OpenAI's file search tool)
- **Tool Choice Control**: `tool_choice` parameter controls whether/how tools are invoked ('auto', 'required', 'none', or specific tool)
- **Parallel Tool Calls**: Support for multiple concurrent tool executions when appropriate
- **Allowed Tools**: Limits which tools the model is permitted to invoke without changing the tools list itself
- **Hosted Tool Requirements**: Custom tools must have corresponding item types that provide receipts of execution

## Streaming Protocols

### Delta Events
- Represent changes to objects since their last update
- Enable incremental communication of updates
- Examples: `response.output_item.added`, `response.output_text.delta`, `response.content_part.done`

### State Machine Events
- Represent changes in the status of objects as they progress through their lifecycle
- Examples: `response.in_progress`, `response.completed`, `response.failed`

### Streaming Sequence
The complete streaming flow follows this pattern:
```
response.output_item.added → response.content_part.added → response.[content-part-type].delta* → response.[content-part-type].done → response.content_part.done → response.output_item.done
```

## Additional Features

### Previous Response ID
- Allows resuming or extending an existing response without resending the entire transcript
- Concatenates: `previous_response.input + previous_response.output + input`
- Preserves semantic order of context

### Tool Choice Options
- `'auto'` (default): Model may call tools or respond directly
- `'required'`: Model must call at least one tool
- `'none'`: Model must not call any tools
- Structured object: Force a specific tool to be used

### Truncation Control
- `'auto'`: Server may truncate earlier context to fit within model's window
- `'disabled'`: Server must not truncate; request fails if context exceeds window

### Service Tier
- Hint about processing urgency and reliability requirements
- Values: 'auto', 'default', 'flex', 'priority'
- Implementation-specific behavior mapping

## Error Handling

- **Structured Errors**: Consistent error objects with `type`, `code`, `param`, and `message` fields
- **Error Types**:
  - `server_error`: Internal server failure (500), retry may succeed
  - `invalid_request`: Malformed request (400), user-resolvable
  - `not_found`: Resource doesn't exist (404)
  - `model_error`: Model failure on valid request (500), not user-resolvable
  - `too_many_requests`: Rate limit exceeded (429), slow down and retry
- **Streaming Errors**: Emitted as events in streaming protocol, followed by `response.failed` event

## API Examples

### Creating a Response
- **Endpoint**: `POST /v1/responses`
- **Description**: Create a streaming response with JSON input and auth header
- **Authentication**: Bearer token in Authorization header

### Creating a Response with Image Input
- **Endpoint**: `POST /v1/responses`
- **Description**: Create a response with image input
- **Content**: Include image URLs in the input with appropriate detail levels

## Extensibility

### Custom Item Types
- Non-standard items must be prefixed with implementor slug (e.g., `acme:custom_item`)
- Must include required fields: `id`, `type`, `status`
- Should be documented for client understanding

### Custom Streaming Events
- Non-standard events must be prefixed with implementor slug (e.g., `acme:custom_event`)
- Should include `type` and `sequence_number` fields
- Clients should be able to ignore unknown events safely

### Schema Extensions
- Implementors may add additional fields to existing schemas
- Extensions should be optional to maintain portability
- Should not alter required core behavior

## Agentic Loop Implementation

The agentic loop follows this sequence:
1. Model analyzes user request
2. Determines if tools are needed
3. Issues tool calls as required
4. Receives tool results
5. Continues processing based on results
6. Generates final response for user

This loop can repeat multiple times within a session, allowing complex workflows involving multiple tools and reasoning steps.

## Compliance and Testing

- **Acceptance Tests**: Comprehensive test suite validates API endpoints for specification compliance
- **Schema Validation**: Tests ensure responses comply with OpenAPI schema
- **Test Categories**: Basic text response, streaming response, system prompt, tool calling, image input, multi-turn conversation
- **Configuration**: Requires base URL, model, API key, and auth header details for testing

## Governance

- **Technical Charter**: Open, vendor-neutral governance structure with clear hierarchy
- **Hierarchy**: Contributors → Maintainers → Core Maintainers → Lead Core Maintainer
- **Decision Making**: Seeks consensus, with majority voting when needed
- **IP Policy**: Contributors retain copyright; specifications under CC-BY-4.0, code under Apache 2.0
- **Vendor Neutrality**: No single vendor controls majority of Core Maintainer seats

## References

- [Specification](https://www.openresponses.org/specification): Complete technical specification with detailed concepts and implementation guidelines
- [API Reference](https://www.openresponses.org/reference): Detailed API documentation with all endpoints, parameters, and response structures
- [Compliance](https://www.openresponses.org/compliance): Acceptance tests and validation procedures
- [Governance](https://www.openresponses.org/governance): Technical charter and governance structure
- [Changelog](https://www.openresponses.org/changelog): Version history and updates